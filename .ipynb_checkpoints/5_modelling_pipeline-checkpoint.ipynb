{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b671eb8-9013-4131-b78c-02e29c11f205",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0079882b-4a22-4589-8129-3cd4fd5122e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>manufacturer_Acer</th>\n",
       "      <th>manufacturer_Apple</th>\n",
       "      <th>manufacturer_Asus</th>\n",
       "      <th>manufacturer_Chuwi</th>\n",
       "      <th>manufacturer_Dell</th>\n",
       "      <th>manufacturer_Fujitsu</th>\n",
       "      <th>manufacturer_Google</th>\n",
       "      <th>manufacturer_HP</th>\n",
       "      <th>manufacturer_Huawei</th>\n",
       "      <th>manufacturer_LG</th>\n",
       "      <th>...</th>\n",
       "      <th>gpu_provider_Nvidia</th>\n",
       "      <th>screen_size</th>\n",
       "      <th>total_pixels</th>\n",
       "      <th>ram</th>\n",
       "      <th>ssd</th>\n",
       "      <th>hdd</th>\n",
       "      <th>hybrid</th>\n",
       "      <th>clock_speed</th>\n",
       "      <th>weight_kg</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>13.3</td>\n",
       "      <td>4096000.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>1.37</td>\n",
       "      <td>11912523.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>13.3</td>\n",
       "      <td>1296000.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1.34</td>\n",
       "      <td>7993374.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>15.6</td>\n",
       "      <td>2073600.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1.86</td>\n",
       "      <td>5112900.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>15.4</td>\n",
       "      <td>5184000.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>512.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.7</td>\n",
       "      <td>1.83</td>\n",
       "      <td>22563005.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>13.3</td>\n",
       "      <td>4096000.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.37</td>\n",
       "      <td>16037611.20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   manufacturer_Acer  manufacturer_Apple  manufacturer_Asus  \\\n",
       "0                  0                   1                  0   \n",
       "1                  0                   1                  0   \n",
       "2                  0                   0                  0   \n",
       "3                  0                   1                  0   \n",
       "4                  0                   1                  0   \n",
       "\n",
       "   manufacturer_Chuwi  manufacturer_Dell  manufacturer_Fujitsu  \\\n",
       "0                   0                  0                     0   \n",
       "1                   0                  0                     0   \n",
       "2                   0                  0                     0   \n",
       "3                   0                  0                     0   \n",
       "4                   0                  0                     0   \n",
       "\n",
       "   manufacturer_Google  manufacturer_HP  manufacturer_Huawei  manufacturer_LG  \\\n",
       "0                    0                0                    0                0   \n",
       "1                    0                0                    0                0   \n",
       "2                    0                1                    0                0   \n",
       "3                    0                0                    0                0   \n",
       "4                    0                0                    0                0   \n",
       "\n",
       "   ...  gpu_provider_Nvidia  screen_size  total_pixels   ram    ssd  hdd  \\\n",
       "0  ...                    0         13.3     4096000.0   8.0  128.0  0.0   \n",
       "1  ...                    0         13.3     1296000.0   8.0    0.0  0.0   \n",
       "2  ...                    0         15.6     2073600.0   8.0  256.0  0.0   \n",
       "3  ...                    0         15.4     5184000.0  16.0  512.0  0.0   \n",
       "4  ...                    0         13.3     4096000.0   8.0  256.0  0.0   \n",
       "\n",
       "   hybrid  clock_speed  weight_kg        price  \n",
       "0     0.0          2.3       1.37  11912523.48  \n",
       "1   128.0          1.8       1.34   7993374.48  \n",
       "2     0.0          2.5       1.86   5112900.00  \n",
       "3     0.0          2.7       1.83  22563005.40  \n",
       "4     0.0          3.1       1.37  16037611.20  \n",
       "\n",
       "[5 rows x 45 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv(\"data/final_train.csv\")\n",
    "\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e066bd1d-efa8-44c1-974d-e09fdb27e9c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>manufacturer_Acer</th>\n",
       "      <th>manufacturer_Apple</th>\n",
       "      <th>manufacturer_Asus</th>\n",
       "      <th>manufacturer_Chuwi</th>\n",
       "      <th>manufacturer_Dell</th>\n",
       "      <th>manufacturer_Fujitsu</th>\n",
       "      <th>manufacturer_Google</th>\n",
       "      <th>manufacturer_HP</th>\n",
       "      <th>manufacturer_Huawei</th>\n",
       "      <th>manufacturer_LG</th>\n",
       "      <th>...</th>\n",
       "      <th>gpu_provider_Nvidia</th>\n",
       "      <th>screen_size</th>\n",
       "      <th>total_pixels</th>\n",
       "      <th>ram</th>\n",
       "      <th>ssd</th>\n",
       "      <th>hdd</th>\n",
       "      <th>hybrid</th>\n",
       "      <th>clock_speed</th>\n",
       "      <th>weight_kg</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>15.6</td>\n",
       "      <td>1049088.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.7</td>\n",
       "      <td>2.04</td>\n",
       "      <td>5148468.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>17.3</td>\n",
       "      <td>2073600.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.8</td>\n",
       "      <td>2.99</td>\n",
       "      <td>15552108.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>15.6</td>\n",
       "      <td>2073600.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>512.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.7</td>\n",
       "      <td>2.19</td>\n",
       "      <td>11550708.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>13.3</td>\n",
       "      <td>2073600.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>1.20</td>\n",
       "      <td>10625940.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>15.6</td>\n",
       "      <td>2073600.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>2.20</td>\n",
       "      <td>4881708.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   manufacturer_Acer  manufacturer_Apple  manufacturer_Asus  \\\n",
       "0                  0                   0                  0   \n",
       "1                  0                   0                  1   \n",
       "2                  0                   0                  0   \n",
       "3                  0                   0                  0   \n",
       "4                  0                   0                  0   \n",
       "\n",
       "   manufacturer_Chuwi  manufacturer_Dell  manufacturer_Fujitsu  \\\n",
       "0                   0                  0                     0   \n",
       "1                   0                  0                     0   \n",
       "2                   0                  1                     0   \n",
       "3                   0                  0                     0   \n",
       "4                   0                  0                     0   \n",
       "\n",
       "   manufacturer_Google  manufacturer_HP  manufacturer_Huawei  manufacturer_LG  \\\n",
       "0                    0                1                    0                0   \n",
       "1                    0                0                    0                0   \n",
       "2                    0                0                    0                0   \n",
       "3                    0                0                    0                0   \n",
       "4                    0                0                    0                0   \n",
       "\n",
       "   ...  gpu_provider_Nvidia  screen_size  total_pixels   ram    ssd     hdd  \\\n",
       "0  ...                    0         15.6     1049088.0   6.0    0.0  1024.0   \n",
       "1  ...                    1         17.3     2073600.0  16.0  256.0  1024.0   \n",
       "2  ...                    0         15.6     2073600.0  12.0  512.0     0.0   \n",
       "3  ...                    0         13.3     2073600.0   4.0  128.0     0.0   \n",
       "4  ...                    0         15.6     2073600.0   6.0  256.0     0.0   \n",
       "\n",
       "   hybrid  clock_speed  weight_kg       price  \n",
       "0     0.0          2.7       2.04   5148468.0  \n",
       "1     0.0          2.8       2.99  15552108.0  \n",
       "2     0.0          2.7       2.19  11550708.0  \n",
       "3     0.0          2.3       1.20  10625940.0  \n",
       "4     0.0          3.6       2.20   4881708.0  \n",
       "\n",
       "[5 rows x 45 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv(\"data/final_test.csv\")\n",
    "\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f57a09f-db5e-4779-adad-087ff101ea90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# Load your data\\ndf = pd.read_csv('your_laptop_data.csv')\\ntest_df = pd.read_csv('your_test_data.csv')  # Optional\\n\\n# Initialize and run pipeline\\npipeline = LaptopPricePredictionPipeline(df, test_df)\\nresults = pipeline.run_pipeline()\\n\\n# Get feature importance\\npipeline.get_feature_importance()\\n\\n# Make predictions on test data\\npredictions = pipeline.predict_test_data()\\n\\n# Use specific model for predictions\\npredictions = pipeline.predict_test_data('Random_Forest')\\n\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class LaptopPricePredictionPipeline:\n",
    "    def __init__(self, df, test_df=None):\n",
    "        self.df = df.copy()\n",
    "        self.test_df = test_df.copy() if test_df is not None else None\n",
    "        self.models = {}\n",
    "        self.best_models = {}\n",
    "        self.results = {}\n",
    "        self.X_train = None\n",
    "        self.X_val = None\n",
    "        self.y_train = None\n",
    "        self.y_val = None\n",
    "        self.scaler = None\n",
    "        \n",
    "    def prepare_data(self):\n",
    "        \"\"\"Prepare features and target, apply scaling and create stratified split\"\"\"\n",
    "        print(\"=== Data Preparation ===\")\n",
    "        \n",
    "        # Separate features and target\n",
    "        X = self.df.drop('price', axis=1)\n",
    "        y = self.df['price']\n",
    "        \n",
    "        print(f\"Dataset shape: {X.shape}\")\n",
    "        print(f\"Target range: ${y.min():,.2f} - ${y.max():,.2f}\")\n",
    "        \n",
    "        # Check for missing values\n",
    "        missing_info = X.isnull().sum()\n",
    "        if missing_info.sum() > 0:\n",
    "            print(\"\\n‚ö†Ô∏è  Missing values found:\")\n",
    "            print(missing_info[missing_info > 0])\n",
    "        else:\n",
    "            print(\"‚úì No missing values in features\")\n",
    "            \n",
    "        # Check for missing values in target\n",
    "        if y.isnull().sum() > 0:\n",
    "            print(f\"‚ö†Ô∏è  Missing values in target: {y.isnull().sum()}\")\n",
    "            # Remove rows with missing target values\n",
    "            mask = ~y.isnull()\n",
    "            X = X[mask]\n",
    "            y = y[mask]\n",
    "            print(f\"‚úì Removed rows with missing target. New shape: {X.shape}\")\n",
    "        \n",
    "        # Create price bins for stratified sampling\n",
    "        y_bins = pd.qcut(y, q=5, labels=False, duplicates='drop')\n",
    "        \n",
    "        # Split the data (80-20)\n",
    "        self.X_train, self.X_val, self.y_train, self.y_val = train_test_split(\n",
    "            X, y, test_size=0.2, random_state=42, stratify=y_bins\n",
    "        )\n",
    "        \n",
    "        print(f\"Training set: {self.X_train.shape}\")\n",
    "        print(f\"Validation set: {self.X_val.shape}\")\n",
    "        print(\"‚úì Data preparation completed\")\n",
    "        \n",
    "    def define_models(self):\n",
    "        \"\"\"Define all models with their parameter grids\"\"\"\n",
    "        \n",
    "        # Model definitions with hyperparameter grids\n",
    "        self.models = {\n",
    "            'Linear_Regression': {\n",
    "                'model': Pipeline([\n",
    "                    ('imputer', SimpleImputer(strategy='median')),\n",
    "                    ('scaler', RobustScaler()),\n",
    "                    ('regressor', LinearRegression())\n",
    "                ]),\n",
    "                'params': {}\n",
    "            },\n",
    "            \n",
    "            'Ridge_Regression': {\n",
    "                'model': Pipeline([\n",
    "                    ('imputer', SimpleImputer(strategy='median')),\n",
    "                    ('scaler', RobustScaler()),\n",
    "                    ('regressor', Ridge(random_state=42))\n",
    "                ]),\n",
    "                'params': {\n",
    "                    'regressor__alpha': [0.1, 1.0, 10.0, 100.0, 1000.0],\n",
    "                    'regressor__solver': ['auto', 'svd', 'saga']\n",
    "                }\n",
    "            },\n",
    "            \n",
    "            'Lasso_Regression': {\n",
    "                'model': Pipeline([\n",
    "                    ('imputer', SimpleImputer(strategy='median')),\n",
    "                    ('scaler', RobustScaler()),\n",
    "                    ('regressor', Lasso(random_state=42, max_iter=2000))\n",
    "                ]),\n",
    "                'params': {\n",
    "                    'regressor__alpha': [0.01, 0.1, 1.0, 10.0, 100.0],\n",
    "                    'regressor__selection': ['cyclic', 'random']\n",
    "                }\n",
    "            },\n",
    "            \n",
    "            'ElasticNet_Regression': {\n",
    "                'model': Pipeline([\n",
    "                    ('imputer', SimpleImputer(strategy='median')),\n",
    "                    ('scaler', RobustScaler()),\n",
    "                    ('regressor', ElasticNet(random_state=42, max_iter=2000))\n",
    "                ]),\n",
    "                'params': {\n",
    "                    'regressor__alpha': [0.01, 0.1, 1.0, 10.0],\n",
    "                    'regressor__l1_ratio': [0.1, 0.3, 0.5, 0.7, 0.9],\n",
    "                }\n",
    "            },\n",
    "            \n",
    "            'Random_Forest': {\n",
    "                'model': Pipeline([\n",
    "                    ('imputer', SimpleImputer(strategy='median')),\n",
    "                    ('regressor', RandomForestRegressor(random_state=42, n_jobs=-1))\n",
    "                ]),\n",
    "                'params': {\n",
    "                    'regressor__n_estimators': [100, 200, 300],\n",
    "                    'regressor__max_depth': [10, 20, None],\n",
    "                    'regressor__min_samples_split': [2, 5, 10],\n",
    "                    'regressor__min_samples_leaf': [1, 2, 4],\n",
    "                    'regressor__max_features': ['sqrt', 'log2']\n",
    "                }\n",
    "            },\n",
    "            \n",
    "            'Gradient_Boosting': {\n",
    "                'model': Pipeline([\n",
    "                    ('imputer', SimpleImputer(strategy='median')),\n",
    "                    ('regressor', GradientBoostingRegressor(random_state=42))\n",
    "                ]),\n",
    "                'params': {\n",
    "                    'regressor__n_estimators': [100, 200, 300],\n",
    "                    'regressor__max_depth': [3, 5, 7],\n",
    "                    'regressor__learning_rate': [0.01, 0.1, 0.2],\n",
    "                    'regressor__subsample': [0.8, 0.9, 1.0],\n",
    "                    'regressor__min_samples_split': [2, 5, 10]\n",
    "                }\n",
    "            },\n",
    "            \n",
    "            'XGBoost': {\n",
    "                'model': Pipeline([\n",
    "                    ('imputer', SimpleImputer(strategy='median')),\n",
    "                    ('regressor', xgb.XGBRegressor(random_state=42, n_jobs=-1))\n",
    "                ]),\n",
    "                'params': {\n",
    "                    'regressor__n_estimators': [100, 200, 300],\n",
    "                    'regressor__max_depth': [3, 5, 7],\n",
    "                    'regressor__learning_rate': [0.01, 0.1, 0.2],\n",
    "                    'regressor__subsample': [0.8, 0.9, 1.0],\n",
    "                    'regressor__colsample_bytree': [0.8, 0.9, 1.0],\n",
    "                    'regressor__reg_alpha': [0, 0.1, 1],\n",
    "                    'regressor__reg_lambda': [1, 1.5, 2]\n",
    "                }\n",
    "            },\n",
    "            \n",
    "            'LightGBM': {\n",
    "                'model': Pipeline([\n",
    "                    ('imputer', SimpleImputer(strategy='median')),\n",
    "                    ('regressor', lgb.LGBMRegressor(random_state=42, n_jobs=-1, verbose=-1))\n",
    "                ]),\n",
    "                'params': {\n",
    "                    'regressor__n_estimators': [100, 200, 300],\n",
    "                    'regressor__max_depth': [3, 5, 7],\n",
    "                    'regressor__learning_rate': [0.01, 0.1, 0.2],\n",
    "                    'regressor__subsample': [0.8, 0.9, 1.0],\n",
    "                    'regressor__colsample_bytree': [0.8, 0.9, 1.0],\n",
    "                    'regressor__reg_alpha': [0, 0.1, 1],\n",
    "                    'regressor__reg_lambda': [1, 1.5, 2]\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "        \n",
    "    def train_models(self):\n",
    "        \"\"\"Train all models with hyperparameter tuning using GridSearchCV\"\"\"\n",
    "        print(\"\\n=== Model Training with Hyperparameter Tuning ===\")\n",
    "        \n",
    "        for name, model_config in self.models.items():\n",
    "            print(f\"\\nTraining {name}...\")\n",
    "            \n",
    "            try:\n",
    "                if model_config['params']:\n",
    "                    # Use GridSearchCV for hyperparameter tuning\n",
    "                    grid_search = GridSearchCV(\n",
    "                        model_config['model'], \n",
    "                        model_config['params'],\n",
    "                        cv=5,\n",
    "                        scoring='neg_mean_squared_error',\n",
    "                        n_jobs=-1,\n",
    "                        verbose=0\n",
    "                    )\n",
    "                    grid_search.fit(self.X_train, self.y_train)\n",
    "                    self.best_models[name] = grid_search.best_estimator_\n",
    "                    print(f\"‚úì Best params for {name}: {grid_search.best_params_}\")\n",
    "                else:\n",
    "                    # For models without hyperparameters (Linear Regression)\n",
    "                    model_config['model'].fit(self.X_train, self.y_train)\n",
    "                    self.best_models[name] = model_config['model']\n",
    "                    print(f\"‚úì {name} trained successfully\")\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"‚úó Error training {name}: {str(e)}\")\n",
    "                \n",
    "        print(f\"\\n‚úì Successfully trained {len(self.best_models)} models\")\n",
    "        \n",
    "    def evaluate_models(self):\n",
    "        \"\"\"Evaluate all trained models\"\"\"\n",
    "        print(\"\\n=== Model Evaluation ===\")\n",
    "        self.results = {}\n",
    "        \n",
    "        for name, model in self.best_models.items():\n",
    "            try:\n",
    "                # Make predictions\n",
    "                y_train_pred = model.predict(self.X_train)\n",
    "                y_val_pred = model.predict(self.X_val)\n",
    "                \n",
    "                # Calculate metrics\n",
    "                train_metrics = self._calculate_metrics(self.y_train, y_train_pred)\n",
    "                val_metrics = self._calculate_metrics(self.y_val, y_val_pred)\n",
    "                \n",
    "                # Cross-validation score\n",
    "                cv_scores = cross_val_score(model, self.X_train, self.y_train, \n",
    "                                          cv=5, scoring='neg_mean_squared_error')\n",
    "                cv_rmse = np.sqrt(-cv_scores.mean())\n",
    "                \n",
    "                self.results[name] = {\n",
    "                    'train_metrics': train_metrics,\n",
    "                    'val_metrics': val_metrics,\n",
    "                    'cv_rmse': cv_rmse,\n",
    "                    'cv_std': np.sqrt(-cv_scores).std()\n",
    "                }\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"‚úó Error evaluating {name}: {str(e)}\")\n",
    "        \n",
    "        self._display_results()\n",
    "        \n",
    "    def _calculate_metrics(self, y_true, y_pred):\n",
    "        \"\"\"Calculate regression metrics\"\"\"\n",
    "        return {\n",
    "            'RMSE': np.sqrt(mean_squared_error(y_true, y_pred)),\n",
    "            'MAE': mean_absolute_error(y_true, y_pred),\n",
    "            'R2': r2_score(y_true, y_pred),\n",
    "            'MAPE': np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "        }\n",
    "    \n",
    "    def _display_results(self):\n",
    "        \"\"\"Display evaluation results in a formatted table\"\"\"\n",
    "        print(\"\\n\" + \"=\"*100)\n",
    "        print(f\"{'Model':<20} {'Train R¬≤':<10} {'Val R¬≤':<10} {'Train RMSE':<12} {'Val RMSE':<12} {'CV RMSE':<12} {'MAPE(%)':<10}\")\n",
    "        print(\"=\"*100)\n",
    "        \n",
    "        sorted_models = sorted(self.results.items(), \n",
    "                             key=lambda x: x[1]['val_metrics']['R2'], reverse=True)\n",
    "        \n",
    "        for name, metrics in sorted_models:\n",
    "            train_r2 = metrics['train_metrics']['R2']\n",
    "            val_r2 = metrics['val_metrics']['R2']\n",
    "            train_rmse = metrics['train_metrics']['RMSE']\n",
    "            val_rmse = metrics['val_metrics']['RMSE']\n",
    "            cv_rmse = metrics['cv_rmse']\n",
    "            mape = metrics['val_metrics']['MAPE']\n",
    "            \n",
    "            print(f\"{name:<20} {train_r2:<10.4f} {val_r2:<10.4f} {train_rmse:<12.0f} \"\n",
    "                  f\"{val_rmse:<12.0f} {cv_rmse:<12.0f} {mape:<10.2f}\")\n",
    "        \n",
    "        print(\"=\"*100)\n",
    "        \n",
    "        # Best model\n",
    "        best_model_name = sorted_models[0][0]\n",
    "        print(f\"\\nüèÜ Best Model: {best_model_name}\")\n",
    "        print(f\"Validation R¬≤: {sorted_models[0][1]['val_metrics']['R2']:.4f}\")\n",
    "        print(f\"Validation RMSE: ${sorted_models[0][1]['val_metrics']['RMSE']:,.2f}\")\n",
    "        \n",
    "    def predict_test_data(self, model_name=None):\n",
    "        \"\"\"Make predictions on test data\"\"\"\n",
    "        if self.test_df is None:\n",
    "            print(\"No test data provided\")\n",
    "            return None\n",
    "            \n",
    "        if model_name is None:\n",
    "            # Use best model\n",
    "            model_name = max(self.results.keys(), \n",
    "                           key=lambda x: self.results[x]['val_metrics']['R2'])\n",
    "        \n",
    "        if model_name not in self.best_models:\n",
    "            print(f\"Model {model_name} not found\")\n",
    "            return None\n",
    "            \n",
    "        # Make predictions (pipeline handles imputation and scaling automatically)\n",
    "        predictions = self.best_models[model_name].predict(self.test_df)\n",
    "        \n",
    "        print(f\"\\n=== Test Predictions using {model_name} ===\")\n",
    "        print(f\"Predictions range: ${predictions.min():,.2f} - ${predictions.max():,.2f}\")\n",
    "        print(f\"Mean prediction: ${predictions.mean():,.2f}\")\n",
    "        \n",
    "        return predictions\n",
    "    \n",
    "    def get_feature_importance(self, model_name=None):\n",
    "        \"\"\"Get feature importance for tree-based models\"\"\"\n",
    "        if model_name is None:\n",
    "            model_name = max(self.results.keys(), \n",
    "                           key=lambda x: self.results[x]['val_metrics']['R2'])\n",
    "        \n",
    "        model = self.best_models[model_name]\n",
    "        \n",
    "        # Extract the actual regressor from pipeline\n",
    "        regressor = model.named_steps['regressor']\n",
    "        \n",
    "        if hasattr(regressor, 'feature_importances_'):\n",
    "            importances = regressor.feature_importances_\n",
    "            feature_names = self.X_train.columns\n",
    "            \n",
    "            importance_df = pd.DataFrame({\n",
    "                'feature': feature_names,\n",
    "                'importance': importances\n",
    "            }).sort_values('importance', ascending=False)\n",
    "            \n",
    "            print(f\"\\n=== Feature Importance ({model_name}) ===\")\n",
    "            print(importance_df.head(10).to_string(index=False))\n",
    "            return importance_df\n",
    "        else:\n",
    "            print(f\"Feature importance not available for {model_name}\")\n",
    "            return None\n",
    "    \n",
    "    def run_pipeline(self):\n",
    "        \"\"\"Run the complete ML pipeline\"\"\"\n",
    "        print(\"üöÄ Starting Laptop Price Prediction ML Pipeline\")\n",
    "        print(\"-\" * 60)\n",
    "        \n",
    "        self.prepare_data()\n",
    "        self.define_models()\n",
    "        self.train_models()\n",
    "        self.evaluate_models()\n",
    "        \n",
    "        print(\"\\n‚úÖ Pipeline completed successfully!\")\n",
    "        return self.results\n",
    "\n",
    "# Usage Example:\n",
    "\"\"\"\n",
    "# Load your data\n",
    "df = pd.read_csv('your_laptop_data.csv')\n",
    "test_df = pd.read_csv('your_test_data.csv')  # Optional\n",
    "\n",
    "# Initialize and run pipeline\n",
    "pipeline = LaptopPricePredictionPipeline(df, test_df)\n",
    "results = pipeline.run_pipeline()\n",
    "\n",
    "# Get feature importance\n",
    "pipeline.get_feature_importance()\n",
    "\n",
    "# Make predictions on test data\n",
    "predictions = pipeline.predict_test_data()\n",
    "\n",
    "# Use specific model for predictions\n",
    "predictions = pipeline.predict_test_data('Random_Forest')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed14c76b-4eb3-4dbd-9234-e08a86db13ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Starting Laptop Price Prediction ML Pipeline\n",
      "------------------------------------------------------------\n",
      "=== Data Preparation ===\n",
      "Dataset shape: (977, 44)\n",
      "Target range: $1,706,374.80 - $54,232,308.00\n",
      "\n",
      "‚ö†Ô∏è  Missing values found:\n",
      "weight_kg    44\n",
      "dtype: int64\n",
      "Training set: (781, 44)\n",
      "Validation set: (196, 44)\n",
      "‚úì Data preparation completed\n",
      "\n",
      "=== Model Training with Hyperparameter Tuning ===\n",
      "\n",
      "Training Linear_Regression...\n",
      "‚úì Linear_Regression trained successfully\n",
      "\n",
      "Training Ridge_Regression...\n",
      "‚úì Best params for Ridge_Regression: {'regressor__alpha': 1.0, 'regressor__solver': 'svd'}\n",
      "\n",
      "Training Lasso_Regression...\n",
      "‚úì Best params for Lasso_Regression: {'regressor__alpha': 0.01, 'regressor__selection': 'cyclic'}\n",
      "\n",
      "Training ElasticNet_Regression...\n",
      "‚úì Best params for ElasticNet_Regression: {'regressor__alpha': 0.01, 'regressor__l1_ratio': 0.9}\n",
      "\n",
      "Training Random_Forest...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m pipeline \u001b[38;5;241m=\u001b[39m LaptopPricePredictionPipeline(df_train, df_test)\n\u001b[1;32m----> 2\u001b[0m results \u001b[38;5;241m=\u001b[39m pipeline\u001b[38;5;241m.\u001b[39mrun_pipeline()\n",
      "Cell \u001b[1;32mIn[4], line 338\u001b[0m, in \u001b[0;36mLaptopPricePredictionPipeline.run_pipeline\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    336\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_data()\n\u001b[0;32m    337\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefine_models()\n\u001b[1;32m--> 338\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_models()\n\u001b[0;32m    339\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluate_models()\n\u001b[0;32m    341\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m‚úÖ Pipeline completed successfully!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[4], line 197\u001b[0m, in \u001b[0;36mLaptopPricePredictionPipeline.train_models\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    187\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m model_config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparams\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[0;32m    188\u001b[0m     \u001b[38;5;66;03m# Use GridSearchCV for hyperparameter tuning\u001b[39;00m\n\u001b[0;32m    189\u001b[0m     grid_search \u001b[38;5;241m=\u001b[39m GridSearchCV(\n\u001b[0;32m    190\u001b[0m         model_config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m], \n\u001b[0;32m    191\u001b[0m         model_config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparams\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    195\u001b[0m         verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    196\u001b[0m     )\n\u001b[1;32m--> 197\u001b[0m     grid_search\u001b[38;5;241m.\u001b[39mfit(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mX_train, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my_train)\n\u001b[0;32m    198\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbest_models[name] \u001b[38;5;241m=\u001b[39m grid_search\u001b[38;5;241m.\u001b[39mbest_estimator_\n\u001b[0;32m    199\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m‚úì Best params for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgrid_search\u001b[38;5;241m.\u001b[39mbest_params_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\datapy\\Lib\\site-packages\\sklearn\\base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1387\u001b[0m     )\n\u001b[0;32m   1388\u001b[0m ):\n\u001b[1;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\datapy\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1024\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m   1018\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m   1019\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m   1020\u001b[0m     )\n\u001b[0;32m   1022\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m-> 1024\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_search(evaluate_candidates)\n\u001b[0;32m   1026\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m   1027\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m   1028\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\datapy\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1571\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1569\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1570\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1571\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_grid))\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\datapy\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:970\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    962\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    963\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    964\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    965\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    966\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    967\u001b[0m         )\n\u001b[0;32m    968\u001b[0m     )\n\u001b[1;32m--> 970\u001b[0m out \u001b[38;5;241m=\u001b[39m parallel(\n\u001b[0;32m    971\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    972\u001b[0m         clone(base_estimator),\n\u001b[0;32m    973\u001b[0m         X,\n\u001b[0;32m    974\u001b[0m         y,\n\u001b[0;32m    975\u001b[0m         train\u001b[38;5;241m=\u001b[39mtrain,\n\u001b[0;32m    976\u001b[0m         test\u001b[38;5;241m=\u001b[39mtest,\n\u001b[0;32m    977\u001b[0m         parameters\u001b[38;5;241m=\u001b[39mparameters,\n\u001b[0;32m    978\u001b[0m         split_progress\u001b[38;5;241m=\u001b[39m(split_idx, n_splits),\n\u001b[0;32m    979\u001b[0m         candidate_progress\u001b[38;5;241m=\u001b[39m(cand_idx, n_candidates),\n\u001b[0;32m    980\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_and_score_kwargs,\n\u001b[0;32m    981\u001b[0m     )\n\u001b[0;32m    982\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[38;5;129;01min\u001b[39;00m product(\n\u001b[0;32m    983\u001b[0m         \u001b[38;5;28menumerate\u001b[39m(candidate_params),\n\u001b[0;32m    984\u001b[0m         \u001b[38;5;28menumerate\u001b[39m(cv\u001b[38;5;241m.\u001b[39msplit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mrouted_params\u001b[38;5;241m.\u001b[39msplitter\u001b[38;5;241m.\u001b[39msplit)),\n\u001b[0;32m    985\u001b[0m     )\n\u001b[0;32m    986\u001b[0m )\n\u001b[0;32m    988\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    989\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    990\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    991\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    992\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    993\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\datapy\\Lib\\site-packages\\sklearn\\utils\\parallel.py:77\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     72\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     73\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     74\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     76\u001b[0m )\n\u001b[1;32m---> 77\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\datapy\\Lib\\site-packages\\joblib\\parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[0;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[0;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[0;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[0;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\datapy\\Lib\\site-packages\\joblib\\parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[1;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[0;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[0;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[0;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[0;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[0;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[0;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[0;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\datapy\\Lib\\site-packages\\joblib\\parallel.py:1762\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[0;32m   1760\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[0;32m   1761\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[1;32m-> 1762\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0.01\u001b[39m)\n\u001b[0;32m   1763\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[0;32m   1766\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[0;32m   1767\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "pipeline = LaptopPricePredictionPipeline(df_train, df_test)\n",
    "results = pipeline.run_pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f60717-5bfa-4b18-b04f-df9e66fb5e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.get_feature_importance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc47daf-7414-40c5-b4a3-28f9fee7c124",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pipeline.predict_test_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f782d49b-9212-4855-86c2-3fbf0be44d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pipeline.predict_test_data('Random_Forest')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
